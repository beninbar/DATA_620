{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0017a4",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  [UCI Machine Learning Repository: Spambase Data Set](http://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "#### Approach\n",
    "For this assignment, we decided to go with text readily available in the Brown corpus of the NLTK package, since the UCI data lacked direct column headers, and variable word counts did not specify which word was being counted, thus complicating the interpetation. Instead, we trained a classifier based on the `humor` and `science_fiction` categories in the corpus and compared the accuracy of classification to a withheld test set from those categories. To do this, we had to create multiple shorter documents out of these two corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a403e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776 11762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "humor = [w.lower() for w in brown.words(categories='humor') if w.isalpha()]\n",
    "scifi = [w.lower() for w in brown.words(categories='science_fiction') if w.isalpha()]\n",
    "print(len(humor), len(scifi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16ad67",
   "metadata": {},
   "source": [
    "We based our code heavily on *Natural Language Processing with Python* chapter 6, essentially by using the top 2000 words for both categories combined as our feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3d02fd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': True,\n",
       " 'of': True,\n",
       " 'and': True,\n",
       " 'to': True,\n",
       " 'a': True,\n",
       " 'in': True,\n",
       " 'was': True,\n",
       " 'he': True,\n",
       " 'that': True,\n",
       " 'it': True,\n",
       " 'i': True,\n",
       " 'had': True,\n",
       " 'for': True,\n",
       " 'his': True,\n",
       " 'you': True,\n",
       " 'on': True,\n",
       " 'with': True,\n",
       " 'as': True,\n",
       " 'but': True,\n",
       " 'not': True}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "\n",
    "combined = humor + scifi\n",
    "all_words = nltk.FreqDist(combined)\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['%s' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "import itertools\n",
    "dict(itertools.islice(document_features(combined).items(), 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8ad45",
   "metadata": {},
   "source": [
    "Then, in order to have something to classify, and be able to split our features documents into training and test sets, we had to subdivide our corpora into various shorter document sizes. Keeping each document at a fairly arbitrary 1000 words, meant subdividing the humorous corpus into 18 documents, and the scifi corpus into 12 documents (using a quick calculation). This gave us a featureset of 30 documents to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "12ad4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "humor_subdiv=[]\n",
    "for i in range(round(len(humor)/1000)):\n",
    "    humor_subdiv.append([humor[i*1000:(i+1)*1000], 'humor'])\n",
    "\n",
    "scifi_subdiv=[]\n",
    "for i in range(round(len(scifi)/1000)):\n",
    "    scifi_subdiv.append([scifi[i*1000:(i+1)*1000], 'scifi'])\n",
    "\n",
    "documents = humor_subdiv+scifi_subdiv\n",
    "\n",
    "# for i in documents:\n",
    "#     for x in i:\n",
    "#         print(len(x), end=' ')\n",
    "#         print(x[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8ab7b",
   "metadata": {},
   "source": [
    "Now we can run our feature extractor on each of the documents we've created, and split the resultant `featuresets` into training and test sets, using an 80-20 split. We shuffle the documents to make sure this split is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcda6c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(documents)\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "\n",
    "train_set, test_set = featuresets[24:], featuresets[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a1899",
   "metadata": {},
   "source": [
    "The final step is to run our Naive Bayes Classifier. We got an accuracy of 0.83, which isn't too bad. This isn't a bad accuracy, but we can probably do better if we remove stopwords, and possibly if we lemmatize our training corpus first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ff857707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our Naive Bayes classifier:  0.8333333333333334 \n",
      "\n",
      "Most Informative Features\n",
      "                  actual = False           humor : scifi  =      2.3 : 1.0\n",
      "                   after = True            humor : scifi  =      2.3 : 1.0\n",
      "                   again = False           scifi : humor  =      2.3 : 1.0\n",
      "                although = False           humor : scifi  =      2.3 : 1.0\n",
      "                  around = True            scifi : humor  =      2.3 : 1.0\n",
      "                     ask = False           humor : scifi  =      2.3 : 1.0\n",
      "                audience = False           scifi : humor  =      2.3 : 1.0\n",
      "                 because = False           scifi : humor  =      2.3 : 1.0\n",
      "                  beside = False           humor : scifi  =      2.3 : 1.0\n",
      "                  bitter = False           scifi : humor  =      2.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print('Accuracy of our Naive Bayes classifier: ', nltk.classify.accuracy(classifier, test_set), '\\n')\n",
    "\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440dbde",
   "metadata": {},
   "source": [
    "Let's remove stopwords. We can see that stopwords account for about 50% of each category's corpus of words. That's a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "78b544e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of stopwords in humor corpus:  0.5015751575157515 \n",
      " Fraction of stopwords in scifi corpus  0.5006801564359803\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "print(\"Fraction of stopwords in humor corpus: \", content_fraction(humor), \"\\n\",\n",
    "      \"Fraction of stopwords in scifi corpus \", content_fraction(scifi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e0570038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return content\n",
    "\n",
    "humor_nostop = remove_stopwords(humor)\n",
    "scifi_nostop = remove_stopwords(scifi)\n",
    "\n",
    "len(scifi_nostop)\n",
    "\n",
    "humor_nostop_subdiv=[]\n",
    "for i in range(round(len(humor_nostop)/1000)):\n",
    "    humor_nostop_subdiv.append([humor_nostop[i*1000:(i+1)*1000], 'humor'])\n",
    "\n",
    "scifi_nostop_subdiv=[]\n",
    "for i in range(round(len(scifi_nostop)/1000)):\n",
    "    scifi_nostop_subdiv.append([scifi_nostop[i*1000:(i+1)*1000], 'scifi'])\n",
    "\n",
    "documents_nostop = humor_nostop_subdiv+scifi_nostop_subdiv\n",
    "\n",
    "random.shuffle(documents_nostop)\n",
    "len(documents_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a489e8c",
   "metadata": {},
   "source": [
    "In this case we get 15 documents, and shuffle and split again in an 80-20% fashion. But, before we do that, we want to change our feature extractor to also exclude stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fe042ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'would': True,\n",
       " 'said': True,\n",
       " 'one': True,\n",
       " 'could': True,\n",
       " 'time': True,\n",
       " 'like': True,\n",
       " 'even': True,\n",
       " 'long': True,\n",
       " 'people': True,\n",
       " 'way': True,\n",
       " 'man': True,\n",
       " 'know': True,\n",
       " 'get': True,\n",
       " 'made': True,\n",
       " 'little': True,\n",
       " 'years': True,\n",
       " 'never': True,\n",
       " 'two': True,\n",
       " 'back': True,\n",
       " 'much': True}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ns = humor_nostop + scifi_nostop\n",
    "all_words_ns = nltk.FreqDist(combined_ns)\n",
    "word_features_ns = list(all_words_ns)[:2000]\n",
    "\n",
    "def document_features_ns(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features_ns:\n",
    "        features['%s' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "import itertools\n",
    "dict(itertools.islice(document_features_ns(combined_ns).items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "53c607de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our Naive Bayes classifier:  0.3333333333333333 \n",
      "\n",
      "Most Informative Features\n",
      "                    able = True            scifi : humor  =      1.5 : 1.0\n",
      "                   abuse = False           scifi : humor  =      1.5 : 1.0\n",
      "               according = True            scifi : humor  =      1.5 : 1.0\n",
      "                  action = False           scifi : humor  =      1.5 : 1.0\n",
      "              activities = False           scifi : humor  =      1.5 : 1.0\n",
      "                   actor = False           scifi : humor  =      1.5 : 1.0\n",
      "                 actress = False           scifi : humor  =      1.5 : 1.0\n",
      "                  advice = False           scifi : humor  =      1.5 : 1.0\n",
      "               afternoon = False           scifi : humor  =      1.5 : 1.0\n",
      "                     age = False           scifi : humor  =      1.5 : 1.0\n",
      "                    aged = False           scifi : humor  =      1.5 : 1.0\n",
      "                     ago = True            scifi : humor  =      1.5 : 1.0\n",
      "                  agreed = True            scifi : humor  =      1.5 : 1.0\n",
      "                 already = True            scifi : humor  =      1.5 : 1.0\n",
      "                although = False           scifi : humor  =      1.5 : 1.0\n",
      "               ambiguity = False           scifi : humor  =      1.5 : 1.0\n",
      "               ambiguous = False           scifi : humor  =      1.5 : 1.0\n",
      "                 america = True            scifi : humor  =      1.5 : 1.0\n",
      "                 ancient = False           scifi : humor  =      1.5 : 1.0\n",
      "                 angeles = False           scifi : humor  =      1.5 : 1.0\n",
      "             anniversary = False           scifi : humor  =      1.5 : 1.0\n",
      "               announced = False           scifi : humor  =      1.5 : 1.0\n",
      "                  answer = False           scifi : humor  =      1.5 : 1.0\n",
      "                answered = False           scifi : humor  =      1.5 : 1.0\n",
      "                  anyhow = False           scifi : humor  =      1.5 : 1.0\n",
      "                anything = False           scifi : humor  =      1.5 : 1.0\n",
      "               apartment = True            scifi : humor  =      1.5 : 1.0\n",
      "                apparent = False           scifi : humor  =      1.5 : 1.0\n",
      "              apparently = False           scifi : humor  =      1.5 : 1.0\n",
      "                  appear = False           scifi : humor  =      1.5 : 1.0\n",
      "                appeared = False           scifi : humor  =      1.5 : 1.0\n",
      "              appreciate = False           scifi : humor  =      1.5 : 1.0\n",
      "                    army = False           scifi : humor  =      1.5 : 1.0\n",
      "                     art = False           scifi : humor  =      1.5 : 1.0\n",
      "                     ask = False           scifi : humor  =      1.5 : 1.0\n",
      "                 assured = False           scifi : humor  =      1.5 : 1.0\n",
      "            astronomical = True            scifi : humor  =      1.5 : 1.0\n",
      "                athletic = False           scifi : humor  =      1.5 : 1.0\n",
      "                  attach = False           scifi : humor  =      1.5 : 1.0\n",
      "                attached = False           scifi : humor  =      1.5 : 1.0\n",
      "               attaching = False           scifi : humor  =      1.5 : 1.0\n",
      "                 attempt = False           scifi : humor  =      1.5 : 1.0\n",
      "               attention = False           scifi : humor  =      1.5 : 1.0\n",
      "                 availed = False           scifi : humor  =      1.5 : 1.0\n",
      "                   babes = False           scifi : humor  =      1.5 : 1.0\n",
      "                    back = True            scifi : humor  =      1.5 : 1.0\n",
      "                     bad = False           scifi : humor  =      1.5 : 1.0\n",
      "                  battle = False           scifi : humor  =      1.5 : 1.0\n",
      "                 beaches = False           scifi : humor  =      1.5 : 1.0\n",
      "                  became = False           scifi : humor  =      1.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "featuresets2 = [(document_features_ns(d), c) for (d,c) in documents_nostop]\n",
    "\n",
    "train_set_ns, test_set_ns = featuresets2[12:], featuresets2[:3]\n",
    "\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set_ns)\n",
    "\n",
    "print('Accuracy of our Naive Bayes classifier: ', nltk.classify.accuracy(classifier2, test_set_ns), '\\n')\n",
    "\n",
    "classifier2.show_most_informative_features(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
