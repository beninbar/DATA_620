{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0017a4",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  [UCI Machine Learning Repository: Spambase Data Set](http://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "#### Approach\n",
    "For this assignment, we decided to go with text readily available in the Brown corpus of the NLTK package, since the UCI data lacked direct column headers, and variable word counts did not specify which word was being counted, thus complicating the interpetation. Instead, we trained a classifier based on the `humor` and `science_fiction` categories in the corpus and compared the accuracy of classification to a withheld test set from those categories. To do this, we had to create multiple shorter documents out of these two corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a403e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776 11762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "humor = [w.lower() for w in brown.words(categories='humor') if w.isalpha()]\n",
    "scifi = [w.lower() for w in brown.words(categories='science_fiction') if w.isalpha()]\n",
    "print(len(humor), len(scifi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16ad67",
   "metadata": {},
   "source": [
    "We based our code heavily on *Natural Language Processing with Python* chapter 6, essentially by using the top 2000 words for both categories combined as our feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d02fd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': True,\n",
       " 'of': True,\n",
       " 'and': True,\n",
       " 'to': True,\n",
       " 'a': True,\n",
       " 'in': True,\n",
       " 'was': True,\n",
       " 'he': True,\n",
       " 'that': True,\n",
       " 'it': True,\n",
       " 'i': True,\n",
       " 'had': True,\n",
       " 'for': True,\n",
       " 'his': True,\n",
       " 'you': True,\n",
       " 'on': True,\n",
       " 'with': True,\n",
       " 'as': True,\n",
       " 'but': True,\n",
       " 'not': True}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined = humor + scifi\n",
    "all_words = nltk.FreqDist(combined)\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['%s' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "import itertools\n",
    "dict(itertools.islice(document_features(combined).items(), 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8ad45",
   "metadata": {},
   "source": [
    "Then, in order to have something to classify, and be able to split our features documents into training and test sets, we had to subdivide our corpora into various shorter document sizes. Keeping each document at an arbitrary 1000 words meant subdividing the humorous corpus into 18 documents, and the scifi corpus into 12 documents. This gave us a featureset of 30 documents to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ad4a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "humor_subdiv=[]\n",
    "for i in range(18):\n",
    "    humor_subdiv.append([humor[i*1000:(i+1)*1000], 'humor'])\n",
    "\n",
    "scifi_subdiv=[]\n",
    "for i in range(12):\n",
    "    scifi_subdiv.append([scifi[i*1000:(i+1)*1000], 'scifi'])\n",
    "\n",
    "documents = humor_subdiv+scifi_subdiv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8ab7b",
   "metadata": {},
   "source": [
    "Now we can run our feature extractor on each of the documents we've created, and split the resultant `featuresets` into training and test sets. We shuffle the documents to get a random split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcda6c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(documents)\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "\n",
    "train_set, test_set = featuresets[24:], featuresets[:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a1899",
   "metadata": {},
   "source": [
    "The final step is to run our Naive Bayes Classifier. Unfortunately, we only get an accuracy of 0.67. This could be due to the relatively small size of our input corpora (~8000 words total), and the fact that we had to subdivide it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff857707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our Naive Bayes classifier:  0.6666666666666666 \n",
      "\n",
      "Most Informative Features\n",
      "                although = True            scifi : humor  =      2.8 : 1.0\n",
      "                 another = True            scifi : humor  =      2.8 : 1.0\n",
      "                    come = True            scifi : humor  =      2.8 : 1.0\n",
      "                 company = True            scifi : humor  =      2.8 : 1.0\n",
      "                    eyes = False           scifi : humor  =      2.8 : 1.0\n",
      "                    feet = False           scifi : humor  =      2.8 : 1.0\n",
      "                    five = False           scifi : humor  =      2.8 : 1.0\n",
      "                    hear = False           scifi : humor  =      2.8 : 1.0\n",
      "                   hello = True            scifi : humor  =      2.8 : 1.0\n",
      "                 kitchen = False           scifi : humor  =      2.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print('Accuracy of our Naive Bayes classifier: ', nltk.classify.accuracy(classifier, test_set), '\\n')\n",
    "\n",
    "classifier.show_most_informative_features()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
