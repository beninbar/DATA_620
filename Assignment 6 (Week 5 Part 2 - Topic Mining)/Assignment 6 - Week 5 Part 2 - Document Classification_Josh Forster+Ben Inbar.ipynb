{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f0017a4",
   "metadata": {},
   "source": [
    "#### Assignment\n",
    "It can be useful to be able to classify new \"test\" documents using already classified \"training\" documents.  A common example is using a corpus of labeled spam and ham (non-spam) e-mails to predict whether or not a new document is spam.  Here is one example of such data:  [UCI Machine Learning Repository: Spambase Data Set](http://archive.ics.uci.edu/dataset/94/spambase)\n",
    "\n",
    "For this project, you can either use the above dataset to predict the class of new documents (either withheld from the training dataset or from another source such as your own spam folder).\n",
    "\n",
    "For more adventurous students, you are welcome (encouraged!) to come up a different set of documents (including scraped web pages!?) that have already been classified (e.g. tagged), then analyze these documents to predict how new documents should be classified.\n",
    "\n",
    "#### Approach\n",
    "For this assignment, we decided to go with text readily available in the Brown corpus of the NLTK package, since the UCI data lacked direct column headers, and variable word counts did not specify which word was being counted, thus complicating the interpetation. Instead, we trained a classifier based on the `humor` and `science_fiction` categories in the corpus and compared the accuracy of classification to a withheld test set from those categories. To do this, we had to create multiple shorter documents out of these two corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a403e677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17776 11762\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "\n",
    "humor = [w.lower() for w in brown.words(categories='humor') if w.isalpha()]\n",
    "scifi = [w.lower() for w in brown.words(categories='science_fiction') if w.isalpha()]\n",
    "print(len(humor), len(scifi))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d16ad67",
   "metadata": {},
   "source": [
    "We based our code heavily on *Natural Language Processing with Python* chapter 6, essentially by using the top 2000 words for both categories combined as our feature extractor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3d02fd1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': True,\n",
       " 'of': True,\n",
       " 'and': True,\n",
       " 'to': True,\n",
       " 'a': True,\n",
       " 'in': True,\n",
       " 'was': True,\n",
       " 'he': True,\n",
       " 'that': True,\n",
       " 'it': True,\n",
       " 'i': True,\n",
       " 'had': True,\n",
       " 'for': True,\n",
       " 'his': True,\n",
       " 'you': True,\n",
       " 'on': True,\n",
       " 'with': True,\n",
       " 'as': True,\n",
       " 'but': True,\n",
       " 'not': True}"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(2)\n",
    "\n",
    "combined = humor + scifi\n",
    "all_words = nltk.FreqDist(combined)\n",
    "word_features = list(all_words)[:2000]\n",
    "\n",
    "def document_features(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['%s' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "import itertools\n",
    "dict(itertools.islice(document_features(combined).items(), 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad8ad45",
   "metadata": {},
   "source": [
    "Then, in order to have something to classify, and be able to split our features documents into training and test sets, we had to subdivide our corpora into various shorter document sizes. Keeping each document short was key so that the Naive Bayes classifier had many documents to train on. Longer, but fewer overall documents led to worse results. So we subdivided them into 100 word length documents: the humor corpus into 178 documents, and the scifi corpus into 118 documents. This gave us a featureset of 296 documents to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "12ad4a53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humor_subdiv=[]\n",
    "for i in range(round(len(humor)/100)):\n",
    "    humor_subdiv.append([humor[i*100:(i+1)*100], 'humor'])\n",
    "\n",
    "scifi_subdiv=[]\n",
    "for i in range(round(len(scifi)/100)):\n",
    "    scifi_subdiv.append([scifi[i*100:(i+1)*100], 'scifi'])\n",
    "\n",
    "documents = humor_subdiv+scifi_subdiv\n",
    "\n",
    "#len(scifi_subdiv)\n",
    "# for i in documents:\n",
    "#     for x in i:\n",
    "#         print(len(x), end=' ')\n",
    "#         print(x[-1])\n",
    "\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b8ab7b",
   "metadata": {},
   "source": [
    "Now we can run our feature extractor on each of the documents we've created, and split the resultant `featuresets` into training and test sets, using an 80-20 split. We shuffle the documents to make sure this split is random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "dcda6c4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random.shuffle(documents)\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]\n",
    "\n",
    "train_set, test_set = featuresets[237:], featuresets[:59]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529a1899",
   "metadata": {},
   "source": [
    "The final step is to run our Naive Bayes Classifier. We got an accuracy of 0.83. This isn't a bad accuracy, but perhaps we can probably do better if we remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ff857707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our Naive Bayes classifier:  0.8305084745762712 \n",
      "\n",
      "Most Informative Features\n",
      "                       a = False           scifi : humor  =      6.2 : 1.0\n",
      "                     any = True            scifi : humor  =      6.2 : 1.0\n",
      "                   earth = True            scifi : humor  =      6.2 : 1.0\n",
      "                   since = True            scifi : humor  =      6.2 : 1.0\n",
      "                  before = True            scifi : humor  =      4.8 : 1.0\n",
      "                     cut = True            scifi : humor  =      4.8 : 1.0\n",
      "               equipment = True            scifi : humor  =      4.8 : 1.0\n",
      "                   going = True            scifi : humor  =      4.8 : 1.0\n",
      "                    help = True            scifi : humor  =      4.8 : 1.0\n",
      "                    here = True            scifi : humor  =      4.5 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print('Accuracy of our Naive Bayes classifier: ', nltk.classify.accuracy(classifier, test_set), '\\n')\n",
    "\n",
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440dbde",
   "metadata": {},
   "source": [
    "Let's remove stopwords. We can see that stopwords account for about 50% of each category's corpus of words. That's a lot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "78b544e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of stopwords in humor corpus:  0.5015751575157515 \n",
      " Fraction of stopwords in scifi corpus  0.5006801564359803\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def content_fraction(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "print(\"Fraction of stopwords in humor corpus: \", content_fraction(humor), \"\\n\",\n",
    "      \"Fraction of stopwords in scifi corpus \", content_fraction(scifi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "e0570038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "206"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_stopwords(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return content\n",
    "\n",
    "humor_nostop = remove_stopwords(humor)\n",
    "scifi_nostop = remove_stopwords(scifi)\n",
    "\n",
    "len(scifi_nostop)\n",
    "\n",
    "humor_nostop_subdiv=[]\n",
    "for i in range(round(len(humor_nostop)/100)):\n",
    "    humor_nostop_subdiv.append([humor_nostop[i*100:(i+1)*100], 'humor'])\n",
    "\n",
    "scifi_nostop_subdiv=[]\n",
    "for i in range(round(len(scifi_nostop)/50)):\n",
    "    scifi_nostop_subdiv.append([scifi_nostop[i*100:(i+1)*100], 'scifi'])\n",
    "\n",
    "documents_nostop = humor_nostop_subdiv+scifi_nostop_subdiv\n",
    "\n",
    "random.shuffle(documents_nostop)\n",
    "len(documents_nostop)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae84609",
   "metadata": {},
   "source": [
    "In this case we get 206 documents, and shuffle and split again in an 80-20% fashion. But, before we do that, we want to change our feature extractor to also exclude stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "fe042ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'would': True,\n",
       " 'said': True,\n",
       " 'one': True,\n",
       " 'could': True,\n",
       " 'time': True,\n",
       " 'like': True,\n",
       " 'even': True,\n",
       " 'long': True,\n",
       " 'people': True,\n",
       " 'way': True,\n",
       " 'man': True,\n",
       " 'know': True,\n",
       " 'get': True,\n",
       " 'made': True,\n",
       " 'little': True,\n",
       " 'years': True,\n",
       " 'never': True,\n",
       " 'two': True,\n",
       " 'back': True,\n",
       " 'much': True}"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_ns = humor_nostop + scifi_nostop\n",
    "all_words_ns = nltk.FreqDist(combined_ns)\n",
    "word_features_ns = list(all_words_ns)[:2000]\n",
    "\n",
    "def document_features_ns(document): \n",
    "    document_words = set(document) \n",
    "    features = {}\n",
    "    for word in word_features_ns:\n",
    "        features['%s' % word] = (word in document_words)\n",
    "    return features\n",
    "\n",
    "import itertools\n",
    "dict(itertools.islice(document_features_ns(combined_ns).items(), 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "09006251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our Naive Bayes classifier:  0.8048780487804879 \n",
      "\n",
      "Most Informative Features\n",
      "                  things = True            humor : scifi  =      9.3 : 1.0\n",
      "                  always = True            humor : scifi  =      5.6 : 1.0\n",
      "                  little = True            humor : scifi  =      5.6 : 1.0\n",
      "                   thing = True            humor : scifi  =      5.6 : 1.0\n",
      "                   woman = True            humor : scifi  =      5.6 : 1.0\n",
      "                    eyes = True            humor : scifi  =      4.4 : 1.0\n",
      "                   right = True            humor : scifi  =      4.4 : 1.0\n",
      "                  seemed = True            humor : scifi  =      4.4 : 1.0\n",
      "                 waiting = True            humor : scifi  =      4.4 : 1.0\n",
      "                  become = True            humor : scifi  =      4.1 : 1.0\n",
      "                 another = True            humor : scifi  =      3.4 : 1.0\n",
      "                    good = True            humor : scifi  =      3.4 : 1.0\n",
      "                   power = True            humor : scifi  =      3.4 : 1.0\n",
      "                     saw = True            humor : scifi  =      3.4 : 1.0\n",
      "                     way = True            humor : scifi  =      3.4 : 1.0\n",
      "                    went = True            humor : scifi  =      3.4 : 1.0\n",
      "                  action = True            humor : scifi  =      3.1 : 1.0\n",
      "                     ago = True            humor : scifi  =      3.1 : 1.0\n",
      "                anything = True            humor : scifi  =      3.1 : 1.0\n",
      "                     box = True            humor : scifi  =      3.1 : 1.0\n",
      "                  broken = True            humor : scifi  =      3.1 : 1.0\n",
      "                    busy = True            humor : scifi  =      3.1 : 1.0\n",
      "                  called = True            humor : scifi  =      3.1 : 1.0\n",
      "                 certain = True            humor : scifi  =      3.1 : 1.0\n",
      "                    dear = True            humor : scifi  =      3.1 : 1.0\n"
     ]
    }
   ],
   "source": [
    "featuresets2 = [(document_features_ns(d), c) for (d,c) in documents_nostop]\n",
    "\n",
    "train_set_ns, test_set_ns = featuresets2[165:], featuresets2[:41]\n",
    "\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set_ns)\n",
    "\n",
    "print('Accuracy of our Naive Bayes classifier: ', nltk.classify.accuracy(classifier2, test_set_ns), '\\n')\n",
    "\n",
    "classifier2.show_most_informative_features(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0857311c",
   "metadata": {},
   "source": [
    "The accuracy actually went down a bit in this case, to 80%, so removing stopwords didn't do much for our classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
